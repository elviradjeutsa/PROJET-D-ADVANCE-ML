{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d50687-63d2-40c7-835f-0e1601f37cfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be779f3-0745-4dc9-8dea-f264f9147b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8b7f24-d000-4989-8d66-4cffd6404c61",
   "metadata": {},
   "source": [
    "Here we instantiate an LSTM cell. W is the weight matrix that applies to the current input, U applies to the hidden state coming from the previous time period and b is the bias matrix. \n",
    "\n",
    "We then initialize the parameters. Biases can be initialized to zero but not the weight matrixes. Otherwise the derivative would be equal to zero and we could not update the weights. Here, we use the Xavier initialization which takes into account the size of the input and output to adjust the standard deviation of the normal distribution used to initialize the values. The mean of this distribution is, of course zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77751ee8-3683-449f-b872-1b332ed8b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Input gate parameters\n",
    "        self.W_i = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_i = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_i = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        # Forget gate parameters\n",
    "        self.W_f = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_f = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_f = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        # Cell gate parameters\n",
    "        self.W_c = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_c = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_c = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        # Output gate parameters\n",
    "        self.W_o = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_o = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_o = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        # Initialize weights\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if \"W_\" in name or \"U_\" in name:  \n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif \"b_\" in name:  \n",
    "                nn.init.zeros_(param)\n",
    "                \n",
    "    def forward(self, x, hidden):\n",
    "        h_prev, c_prev = hidden\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(x.size(1)):\n",
    "            x_t = x[:, t, :]\n",
    "\n",
    "            # Input gate\n",
    "            i_t = torch.sigmoid(x_t @ self.W_i + h_prev @ self.U_i + self.b_i)\n",
    "\n",
    "            # Forget gate\n",
    "            f_t = torch.sigmoid(x_t @ self.W_f + h_prev @ self.U_f + self.b_f)\n",
    "\n",
    "            # Cell gate\n",
    "            g_t = torch.tanh(x_t @ self.W_c + h_prev @ self.U_c + self.b_c)\n",
    "\n",
    "            # Update cell state\n",
    "            c_t = f_t * c_prev + i_t * g_t\n",
    "\n",
    "            # Output gate\n",
    "            o_t = torch.sigmoid(x_t @ self.W_o + h_prev @ self.U_o + self.b_o)\n",
    "\n",
    "            # Update hidden state\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "\n",
    "            outputs.append(h_t.unsqueeze(1))\n",
    "\n",
    "            # Update states for next time step\n",
    "            h_prev, c_prev = h_t, c_t\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e72b7f-3eaf-44b8-a309-f82bc394a1ff",
   "metadata": {},
   "source": [
    "Here, we create the LSTM layers. The for loop in the initialization stacks the cells to create the layers. In the end, we add a linear layer to convert the last hidden state into the output size we desire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c92bc2-6cd2-461d-a9bc-4bd75355b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, output_size=1):\n",
    "        super(StackedLSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_size = input_size if i == 0 else hidden_size\n",
    "            self.layers.append(LSTM(in_size, hidden_size))\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden_states):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            h_prev, c_prev = hidden_states[i]\n",
    "            x, (h, c) = layer(x, (h_prev, c_prev))  # Pass through each LSTM layer\n",
    "\n",
    "        # Use the last time step's hidden state and apply the fully connected layer\n",
    "        outputs = self.fc(x[:, -1, :])  # Shape: (batch_size, output_size)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ab9f5c-d61a-4736-bcd0-fcbd94ab1f1f",
   "metadata": {},
   "source": [
    "We now load the customers of the first cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96bc95da-5686-4c90-9ed9-0c20d1f57377",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = pd.read_csv('cluster_0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1825a0fe-ca6a-40a6-8995-264e41c1d699",
   "metadata": {},
   "source": [
    "For the training, we keep only the customers that were subscribed to the insurance during the three years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "882e0316-9076-4c66-bc3f-053738e7042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to drop rows for a specific year\n",
    "def drop_rows_by_year(df, year):\n",
    "    # Find columns for the given year\n",
    "    year_columns = [col for col in df.columns if col.endswith(str(year)[-2:])]\n",
    "    \n",
    "    # Drop rows where all columns for the year are 0\n",
    "    df = df.loc[~(df[year_columns].sum(axis=1) == 0)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply for each year\n",
    "for year in [2022, 2023, 2024]:\n",
    "    data_merged = drop_rows_by_year(data_merged, year)\n",
    "\n",
    "non_nan_data = data_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8c7f8d-32d5-4635-a269-b240d085c4ae",
   "metadata": {},
   "source": [
    "As our data is not very complex, we run our model on only a subset of the data. Our empirical tests have shown that this does not impede the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9dce956-d1ff-4ca7-817f-02ad3ee65f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_data = non_nan_data.iloc[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de19bc79-bef6-48a7-bb5c-a35927d060eb",
   "metadata": {},
   "source": [
    "We now need to reshape the data so that it can be fed into the network. We now need to reshape the data so that it can be fed into the network. We convert it to a time series format (each row corresponds to a time frame, here a month). Our static features keep the same value for each month. For the other features, which depend on the time frame, we add the value to the adequate row, meaning the corresponding time frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c059b34f-ee1b-4258-ab6f-efef5b4092c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static Data Shape: (2000, 22)\n",
      "Time Data Shape: (2000, 32)\n"
     ]
    }
   ],
   "source": [
    "# Extract time-dependent columns (these will be the targets)\n",
    "time_columns = [col for col in subset_data.columns if col.startswith('ra_')]\n",
    "\n",
    "# Extract static columns (these will be the features)\n",
    "static_columns = ['Age22', 'is_genre_Enfant', 'is_genre_Femme', 'is_genre_Homme', 'is_genre_Pas de donnees', 'is_benef_Autre',\n",
    "                  'is_benef_Conjoint', 'is_benef_Enfant majeur', 'is_benef_Enfant mineur', 'is_benef_Salarié', 'is_foyer_ND',\n",
    "                  'is_foyer_Salarié et 1 enfant', 'is_foyer_Salarié et 2 enfants', 'is_foyer_Salarié et 3+ enfants',\n",
    "                  'is_foyer_Salarié et conjoint et 1 enfant', 'is_foyer_Salarié et conjoint et 2 enfants', \n",
    "                  'is_foyer_Salarié et conjoint et 3+ enfants', 'is_foyer_Salarié et conjoint sans enfant', 'is_foyer_Salarié seul', 'region_ETR',\n",
    "                  'region_IDF', 'region_OTH']  \n",
    "\n",
    "# Create the static feature matrix\n",
    "static_data = subset_data[static_columns].values  # Shape: (num_clients, num_features)\n",
    "\n",
    "# Create the time-dependent target matrix\n",
    "time_data = subset_data[time_columns].values  # Shape: (num_clients, num_time_steps)\n",
    "\n",
    "print(\"Static Data Shape:\", static_data.shape)  # (num_clients, num_features)\n",
    "print(\"Time Data Shape:\", time_data.shape)  # (num_clients, num_time_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1408a17-64b9-46ee-b3da-54ad1f587776",
   "metadata": {},
   "source": [
    "We will now train the model. First we select a certain width (here 24 month) to be used for training. Our model will then make predictions on the next month. We can then convert our values to the tensor format to pass them through our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1ce0cd7-16c7-4840-b78d-f38f7543f01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([8000, 24, 22])\n",
      "Target Shape: torch.Size([8000, 1])\n",
      "Epoch 1/5, Loss: 0.8249\n",
      "Epoch 2/5, Loss: 0.3719\n",
      "Epoch 3/5, Loss: 0.1657\n",
      "Epoch 4/5, Loss: 0.2013\n",
      "Epoch 5/5, Loss: 0.0656\n"
     ]
    }
   ],
   "source": [
    "X, y = [], []\n",
    "sequence_length = 24  # Length of each input sequence\n",
    "\n",
    "# Iterate over clients\n",
    "for client_idx in range(static_data.shape[0]):  # Iterate over each client\n",
    "    client_targets = time_data[client_idx]  # Shape: (num_time_steps,)\n",
    "\n",
    "    # Create sequences for this client\n",
    "    for t in range(len(client_targets) - sequence_length):  # Slide over time steps\n",
    "        # Static features repeated for each time step in the sequence\n",
    "        static_features = static_data[client_idx]  # Shape: (num_features,)\n",
    "        static_repeated = np.tile(static_features, (sequence_length, 1))  # Shape: (seq_len, num_features)\n",
    "    \n",
    "        # Ensure the static features are of type float32 (numeric)\n",
    "        static_repeated = static_repeated.astype(np.float32)\n",
    "    \n",
    "        # Combine static and time-dependent features\n",
    "        X.append(static_repeated)  # Static features remain constant for each sequence\n",
    "        y.append(client_targets[t + sequence_length])  # Target is the value at the next time step\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X)  # Shape: (num_samples, seq_len, num_features)\n",
    "y = np.array(y)  # Shape: (num_samples,)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)  # Shape: (num_samples, seq_len, input_size)\n",
    "y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # Shape: (num_samples, 1)\n",
    "\n",
    "print(\"Input Shape:\", X.shape)  # (num_samples, seq_len, input_size)\n",
    "print(\"Target Shape:\", y.shape)  # (num_samples, 1)\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = static_data.shape[1]  # Number of static features\n",
    "hidden_size = 32  # Size of LSTM hidden states\n",
    "num_layers = 5    # Number of LSTM layers\n",
    "output_size = 1   # Predicting a single value (next step's target)\n",
    "batch_size = 4    # Number of samples per batch\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = torch.utils.data.TensorDataset(X, y)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = StackedLSTM(input_size, hidden_size, num_layers=5)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize hidden and cell states\n",
    "def init_hidden_states(batch_size, num_layers, hidden_size, device):\n",
    "    return [(torch.zeros(batch_size, hidden_size).to(device), torch.zeros(batch_size, hidden_size).to(device)) \n",
    "            for _ in range(num_layers)]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    all_predictions = []\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        batch_X, batch_y = batch_X.to(torch.float32), batch_y.to(torch.float32)\n",
    "\n",
    "        # Initialize hidden states for the batch\n",
    "        hidden_states = init_hidden_states(batch_size, num_layers=5, hidden_size=hidden_size, device=batch_X.device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X, hidden_states)\n",
    "        all_predictions.append(outputs.detach().cpu().numpy())\n",
    "        loss = criterion(outputs, batch_y)  # Direct comparison with targets\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac677a58-b98b-4685-8460-7c20e8eeac98",
   "metadata": {},
   "source": [
    "We will now test our model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c72a3416-191e-466b-91a3-eb4de19bac12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static Data Shape: (1000, 22)\n",
      "Time Data Shape: (1000, 32)\n",
      "Test Input Shape: torch.Size([15500, 24, 22])\n",
      "Test Target Shape: torch.Size([15500, 1])\n",
      "Test Loss: 3.2922\n"
     ]
    }
   ],
   "source": [
    "test_data = non_nan_data.iloc[1000:1500]\n",
    "\n",
    "# Extract time-dependent columns (these will be the targets)\n",
    "time_columns = [col for col in subset_data.columns if col.startswith('ra_')]\n",
    "\n",
    "# Extract static columns (these will be the features)\n",
    "static_columns = ['Age22', 'is_genre_Enfant', 'is_genre_Femme', 'is_genre_Homme', 'is_genre_Pas de donnees', 'is_benef_Autre',\n",
    "                  'is_benef_Conjoint', 'is_benef_Enfant majeur', 'is_benef_Enfant mineur', 'is_benef_Salarié', 'is_foyer_ND',\n",
    "                  'is_foyer_Salarié et 1 enfant', 'is_foyer_Salarié et 2 enfants', 'is_foyer_Salarié et 3+ enfants',\n",
    "                  'is_foyer_Salarié et conjoint et 1 enfant', 'is_foyer_Salarié et conjoint et 2 enfants', \n",
    "                  'is_foyer_Salarié et conjoint et 3+ enfants', 'is_foyer_Salarié et conjoint sans enfant', 'is_foyer_Salarié seul', 'region_ETR',\n",
    "                  'region_IDF', 'region_OTH']  # Static features\n",
    "\n",
    "# Create the static feature matrix\n",
    "static_data = subset_data[static_columns].values  # Shape: (num_clients, num_features)\n",
    "\n",
    "# Create the time-dependent target matrix\n",
    "time_data = subset_data[time_columns].values  # Shape: (num_clients, num_time_steps)\n",
    "\n",
    "print(\"Static Data Shape:\", static_data.shape)  # (num_clients, num_features)\n",
    "print(\"Time Data Shape:\", time_data.shape)  # (num_clients, num_time_steps)\n",
    "\n",
    "\n",
    "# Preprocess test data\n",
    "test_X, test_y = [], []\n",
    "for client_idx in range(test_data.shape[0]):  # Iterate over each client\n",
    "    client_targets = test_data.iloc[client_idx].values  # Assuming time-series data is stored row-wise\n",
    "\n",
    "    for t in range(len(client_targets) - sequence_length):  # Slide over time steps\n",
    "        static_features = static_data[client_idx]  # Use corresponding static data\n",
    "        static_repeated = np.tile(static_features, (sequence_length, 1)).astype(np.float32)\n",
    "        \n",
    "        test_X.append(static_repeated)\n",
    "        test_y.append(client_targets[t + sequence_length])\n",
    "\n",
    "# Convert test data to tensors\n",
    "test_X = torch.tensor(np.array(test_X), dtype=torch.float32)\n",
    "test_y = torch.tensor(np.array(test_y), dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "print(\"Test Input Shape:\", test_X.shape)\n",
    "print(\"Test Target Shape:\", test_y.shape)\n",
    "\n",
    "# Initialize hidden states\n",
    "hidden_states = init_hidden_states(batch_size=test_X.size(0), num_layers=num_layers, hidden_size=hidden_size, device=test_X.device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_X, hidden_states)\n",
    "\n",
    "    test_loss = criterion(predictions, test_y)\n",
    "    print(f\"Test Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "predictions_np = predictions.cpu().numpy()\n",
    "test_y_np = test_y.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4461f1b0-6560-4999-a032-46f7f411e3f6",
   "metadata": {},
   "source": [
    "We can now look at our predictions. We will then compare these values to the predictions in other clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e5766ae-c4e6-4913-8c8b-640405745851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean : 0.25781527\n",
      "Standard deviation : 0.004483249\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean :\", np.mean((predictions_np)))\n",
    "print(\"Standard deviation :\", np.std((predictions_np)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
